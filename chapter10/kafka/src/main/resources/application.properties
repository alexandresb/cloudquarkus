# configuration globale de l'adresse du broker distant - optionnel car localhost:9092 est la valeur par défaut
# on aurait pu configurer pour chaque connecteur : mp.messaging.{outgoing|incoming}.{nom channel}.bootstrap.servers={adresse}
kafka.bootstrap.servers=localhost:9092

#Kafka source : connecteur outbound permettant de mapper la channel stock-quote avec le topic Kafka qui recevra les messages
#ecriture des messages provenant d'OperationGenerator dans le topic Kafka
#on indique le type de connecteur, ici smallrye-kafka
mp.messaging.outgoing.stock-quote.connector=smallrye-kafka
# mapping (branchement) de la channel stock-quote avec le topic stocks pour écriture dans le topic
mp.messaging.outgoing.stock-quote.topic=stocks
# serialiseur utilisé pour convertir les messages de la channel en flux de bits accepté par Kafka
mp.messaging.outgoing.stock-quote.value.serializer=org.apache.kafka.common.serialization.StringSerializer

#Kafka sink : configuration du connecteur inbound pour lire les messages dans le topic kafka. Messages lus par QuoteConverter
mp.messaging.incoming.stocks.connector=smallrye-kafka
#branchement du topic stocks à la channel stocks qui reçoit les messages qui seront consommés par QuoteConverter (processor) - optionnel
mp.messaging.incoming.stocks.topic=stocks
#désérialiseur transformant les messages issues de Kafka en message de type String lisible par le consommateur
mp.messaging.incoming.stocks.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#note : la stratégie de commit /défaut est throttled (le connecteur commite de dans en temps quand un certains nb de messages ont été acquittés)
#note sur concept de connecteur kafka sink / source : dans la doc officielle Quarkus (https://quarkus.io/guides/kafka#configuring-the-kafka-connector)
# Si on se place d'un point de vue Kafka, selon la documentation Kafka Connect, un connecteur source écrit dans Kafka les messages émis par 1 source
# et 1 sink reçoit/extrait les messages. plus généralement 1 source émet des msg / 1 sink réceptionne.
# si on se place d'un point de vue applicatif, le composant "outgoing" utilise un connecteur (client kafka) pour déverser dans kafka qui est un sink.
# Et le composant "incoming" reçoit des messages d'une source Kafka.
